[data]
X_train = <path_to_x_tr_csv>
X_dev = <path_to_x_evaluation_csv>
X_test = <path_to_x_test_csv>
y_train = <path_to_y_tr_csv>
y_dev = <path_to_y_evaluation_csv>
y_test = <path_to_y_test_csv>
series_ids = <variable_names_youd_like_the_software_to_treat_as_separate_time_series>
split_ids = subject sentid
modulus = 4
history_length = <how_many_steps_back_should_be_looked_at>
filters = <semi colon separated filter conditions>

[global_settings]
outdir = <output_directory>

[cdr_settings]
learning_rate = 0.005
minibatch_size = 1024
max_global_gradient_norm = 1
loss_filter_n_sds = 1000
rvs = None
n_units = 32
ranef_l1_only = False
ranef_bias_only = True
layer_normalization_type = None
dropout_rate = 0.1
nn_regularizer_name = l2_regularizer
nn_regularizer_scale = 5
ranef_regularizer_name = l2_regularizer
ranef_regularizer_scale = 1
context_regularizer_name = l1_l2_regularizer
context_regularizer_scale = 10
rescale_t_delta = False
activation = gelu
log_freq = 1
save_freq = 100

generate_irf_surface_plots = False
generate_nonstationarity_surface_plots = False
generate_curvature_plots = False
plot_step_default = sd

[irf_name_map]
rate = Rate
wdelta = Saccade length
prevwasfix = Previous fixated
wlen = Word length
unigramsurp = Unigram surprisal
fwprob5surp = 5-gram surprisal
fdurFP = First pass dur (log-ms)

[model_CDR_b1024]
formula = fdurFP ~ C(rate + wdelta + prevwasfix + wlen + unigramsurp + fwprob5surp, NN()) + (C(rate + wdelta + prevwasfix + wlen + unigramsurp + fwprob5surp, NN(ran=T)) | subject)
